% Generated by roxygen2 (4.0.2): do not edit by hand
\name{index}
\alias{index}
\alias{index_analyze}
\alias{index_close}
\alias{index_create}
\alias{index_delete}
\alias{index_exists}
\alias{index_get}
\alias{index_open}
\alias{index_optimize}
\alias{index_recovery}
\alias{index_segments}
\alias{index_stats}
\alias{index_status}
\alias{index_upgrade}
\title{Elasticsearch indices APIs}
\usage{
index_get(index = NULL, features = NULL, raw = FALSE, callopts = list(),
  verbose = TRUE, ...)

index_exists(index, callopts = list())

index_delete(index, raw = FALSE, callopts = list(), verbose = TRUE)

index_create(index = NULL, type = NULL, id = NULL, fields = NULL,
  raw = FALSE, callopts = list(), verbose = TRUE, ...)

index_close(index, callopts = list())

index_open(index, callopts = list())

index_stats(index = NULL, metric = NULL, completion_fields = NULL,
  fielddata_fields = NULL, fields = NULL, groups = NULL,
  level = "indices", callopts = list())

index_status(index = NULL, callopts = list())

index_segments(index = NULL, callopts = list())

index_recovery(index = NULL, detailed = FALSE, active_only = FALSE,
  callopts = list())

index_optimize(index = NULL, max_num_segments = NULL,
  only_expunge_deletes = FALSE, flush = TRUE, wait_for_merge = TRUE,
  callopts = list())

index_upgrade(index = NULL, wait_for_completion = FALSE,
  callopts = list())

index_analyze(text = NULL, field = NULL, index = NULL, analyzer = NULL,
  tokenizer = NULL, filters = NULL, char_filters = NULL,
  callopts = list())
}
\arguments{
\item{index}{(character) A character vector of index names}

\item{features}{(character) A character vector of features. One or more of settings, mappings,
warmers or aliases}

\item{raw}{If TRUE (default), data is parsed to list. If FALSE, then raw JSON.}

\item{callopts}{Curl args passed on to \code{\link[httr]{POST}}, \code{\link[httr]{GET}},
\code{\link[httr]{PUT}}, \code{\link[httr]{HEAD}}, or \code{\link[httr]{DELETE}}}

\item{verbose}{If TRUE (default) the url call used printed to console.}

\item{...}{Further args passed on to elastic search HTTP API as parameters.}

\item{type}{(character) Document type}

\item{id}{Document id}

\item{fields}{(character) Fields to add.}

\item{metric}{(character) A character vector of metrics to display. Possible values: "_all",
"completion", "docs", "fielddata", "filter_cache", "flush", "get", "id_cache", "indexing",
"merge", "percolate", "refresh", "search", "segments", "store", "warmer".}

\item{completion_fields}{(character) A character vector of fields for completion metric
(supports wildcards)}

\item{fielddata_fields}{(character) A character vector of fields for fielddata metric
(supports wildcards)}

\item{groups}{(character) A character vector of search groups for search statistics.}

\item{level}{(character) Return stats aggregated on "cluster", "indices" (default) or "shards"}

\item{detailed}{(logical) Whether to display detailed information about shard recovery.
Default: FALSE}

\item{active_only}{(logical) Display only those recoveries that are currently on-going.
Default: FALSE}

\item{max_num_segments}{(character) The number of segments the index should be merged into.
Default: "dynamic"}

\item{only_expunge_deletes}{(logical) Specify whether the operation should only expunge
deleted documents}

\item{flush}{(logical) Specify whether the index should be flushed after performing the
operation. Default: TRUE}

\item{wait_for_merge}{(logical) Specify whether the request should block until the merge
process is finished. Default: TRUE}

\item{wait_for_completion}{(logical) Should the request wait for the upgrade to complete.
Default: FALSE}

\item{text}{The text on which the analysis should be performed (when request body is not used)}

\item{field}{Use the analyzer configured for this field (instead of passing the analyzer name)}

\item{analyzer}{The name of the analyzer to use}

\item{tokenizer}{The name of the tokenizer to use for the analysis}

\item{filters}{A character vector of filters to use for the analysis}

\item{char_filters}{A character vector of character filters to use for the analysis}

\item{force}{(logical) Whether a flush should be forced even if it is not necessarily needed
ie. if no changes will be committed to the index.}

\item{full}{(logical) If set to TRUE a new index writer is created and settings that have been
changed related to the index writer will be refreshed.}

\item{wait_if_ongoing}{If TRUE, the flush operation will block until the flush can be executed
if another flush operation is already executing. The default is false and will cause an
exception to be thrown on the shard level if another flush operation is already running.
[1.4.0.Beta1]}

\item{filter}{(logical) Clear filter caches}

\item{filter_keys}{(character) A vector of keys to clear when using the \code{filter_cache}
parameter (default: all)}

\item{fielddata}{(logical) Clear field data}

\item{query_cache}{(logical) Clear query caches}

\item{id_cache}{(logical) Clear ID caches for parent/child}
}
\description{
Elasticsearch indices APIs
}
\details{
\bold{analyze}:
\url{http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-analyze.html}
This method can accept a string of text in the body, but this function passes it as a
parameter in a GET request to simplify.
}
\examples{
\donttest{
# get information on an index
index_get(index='shakespeare')
index_get(index='shakespeare', features=c('settings','mappings'))
index_get(index='shakespeare', features='aliases')
index_get(index='shakespeare', features='warmers')

# check for index existence
index_exists(index='shakespeare')
index_exists(index='plos')

# delete an index
index_delete(index='plos')

# create an index
index_create(index='twitter', type='tweet', id=10)
index_create(index='things', type='tweet', id=10)

# close an index
index_close('plos')

# open an index
index_open('plos')

# Get status of an index
index_status('plos')
index_status(c('plos','gbif'))

# Get stats on an index
index_stats('plos')
index_stats(c('plos','gbif'))
index_stats(c('plos','gbif'), metric='refresh')
index_stats('shakespeare', metric='completion')
index_stats('shakespeare', metric='completion', completion_fields = "completion")
index_stats('shakespeare', metric='fielddata')
index_stats('shakespeare', metric='fielddata', fielddata_fields = "evictions")
index_stats('plos', level="indices")
index_stats('plos', level="cluster")
index_stats('plos', level="shards")

# Get segments information that a Lucene index (shard level) is built with
index_segments()
index_segments('plos')
index_segments(c('plos','gbif'))

# Get recovery information that provides insight into on-going index shard recoveries
index_recovery()
index_recovery('plos')
index_recovery(c('plos','gbif'))
index_recovery("plos", detailed = TRUE)
index_recovery("plos", active_only = TRUE)

# Optimize an index, or many indices
index_optimize('plos')
index_optimize(c('plos','gbif'))

# Upgrade one or more indices to the latest format. The upgrade process converts any
# segments written with previous formats.
index_upgrade('plos')
index_upgrade(c('plos','gbif'))

# Performs the analysis process on a text and return the tokens breakdown of the text.
index_analyze(text = 'this is a test', analyzer='standard')
index_analyze(text = 'this is a test', analyzer='whitespace')
index_analyze(text = 'this is a test', analyzer='stop')
index_analyze(text = 'this is a test', tokenizer='keyword', filters='lowercase')
index_analyze(text = 'this is a test', tokenizer='keyword', filters='lowercase',
   char_filters='html_strip')
index_analyze(text = 'this is a test', index = 'plos')
index_analyze(text = 'this is a test', index = 'shakespeare')
index_analyze(text = 'this is a test', index = 'shakespeare', callopts=verbose())
}
}
\author{
Scott Chamberlain <myrmecocystus@gmail.com>
}
\references{
\url{http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices.html}
}

